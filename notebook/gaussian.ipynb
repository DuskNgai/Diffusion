{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
    "os.environ[\"HF_HOME\"] = str(Path.cwd().joinpath(\"cache\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Scheduler by Gaussian Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "from IPython import get_ipython\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "sys.path.append(Path(get_ipython().run_line_magic(\"pwd\", \"\")).resolve().parent.as_posix())\n",
    "\n",
    "from gaussian import (\n",
    "    GaussianModelPipeline,\n",
    "    GaussianModel,\n",
    "    GaussianModelScheduler\n",
    ")\n",
    "from sampler import SAMPLER_FORMULATION_TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_inference_result(\n",
    "    pipeline: GaussianModelPipeline,\n",
    "    batch_size: int,\n",
    "    num_inference_steps: int,\n",
    "    seed: int\n",
    "):\n",
    "    plt.figure(figsize=(16, 22))\n",
    "\n",
    "    algorithm_types = [\"ode\", \"sde\"]\n",
    "    prediction_types = [\"epsilon\", \"sample\", \"velocity\"]\n",
    "    timestep_schedules = [\"linear_lognsr\", \"cosine_lognsr\", \"power_lognsr\", \"uniform\"]\n",
    "\n",
    "    for row_id, (algorithm_type, prediction_type) in enumerate(itertools.product(algorithm_types, prediction_types)):\n",
    "        pipeline.scheduler.config.algorithm_type = algorithm_type\n",
    "        pipeline.scheduler.config.prediction_type = prediction_type\n",
    "        for col_id, timestep_schedule in enumerate(timestep_schedules):\n",
    "            if algorithm_type == \"sde\" and prediction_type == \"velocity\":\n",
    "                continue\n",
    "            pipeline.scheduler.config.timestep_schedule = timestep_schedule\n",
    "            torch.manual_seed(seed)\n",
    "            torch.cuda.manual_seed(seed)\n",
    "\n",
    "            samples = pipeline(batch_size=batch_size, num_inference_steps=num_inference_steps)\n",
    "            samples = samples.detach().cpu().numpy()\n",
    "            mean, std = samples.mean(axis=0), samples.std(axis=0)\n",
    "            print(f\"{algorithm_type} {prediction_type} {timestep_schedule}: mean={mean}, std={std}\")\n",
    "\n",
    "            plt.subplot(len(algorithm_types) * len(prediction_types), len(timestep_schedules), row_id * len(timestep_schedules) + col_id + 1)\n",
    "            plt.hist2d(samples[:, 0], samples[:, 1], bins=[128, 128], range=[[-4, 4], [-4, 4]], cmap=\"plasma\", cmin=1)\n",
    "            plt.title(f\"{algorithm_type} {prediction_type} {timestep_schedule}\")\n",
    "            plt.axis(\"equal\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "batch_size = 16384\n",
    "num_inference_steps = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = torch.Tensor([0.0, 0.0])\n",
    "cov = torch.Tensor([\n",
    "    [1.0, 0.0],\n",
    "    [0.0, 1.0]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Rectified Flow's Formulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FORMULATION = SAMPLER_FORMULATION_TABLE[\"Rectified Flow\"]\n",
    "\n",
    "pipeline = GaussianModelPipeline(\n",
    "    GaussianModel(mu=mu, cov=cov),\n",
    "    GaussianModelScheduler(\n",
    "        t_min=0 + 1e-4,\n",
    "        t_max=1 - 1e-4,\n",
    "        sigma_data=1.0,\n",
    "        scale_fn=FORMULATION[\"scale_fn\"],\n",
    "        scale_deriv_fn=FORMULATION[\"scale_deriv_fn\"],\n",
    "        sigma_fn=FORMULATION[\"sigma_fn\"],\n",
    "        sigma_deriv_fn=FORMULATION[\"sigma_deriv_fn\"],\n",
    "        nsr_inv_fn=FORMULATION[\"nsr_inv_fn\"],\n",
    "        prediction_type=\"epsilon\",\n",
    "        algorithm_type=\"ode\",\n",
    "        timestep_schedule=\"cosine_lognsr\"\n",
    "    )\n",
    ")\n",
    "if torch.cuda.is_available():\n",
    "    pipeline = pipeline.to(device=torch.device(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_inference_result(pipeline, batch_size, num_inference_steps, seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test EDM's Formulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FORMULATION = SAMPLER_FORMULATION_TABLE[\"EDM\"]\n",
    "\n",
    "pipeline.scheduler = GaussianModelScheduler(\n",
    "    t_min=1e-3,\n",
    "    t_max=1e+3,\n",
    "    sigma_data=1.0,\n",
    "    scale_fn=FORMULATION[\"scale_fn\"],\n",
    "    scale_deriv_fn=FORMULATION[\"scale_deriv_fn\"],\n",
    "    sigma_fn=FORMULATION[\"sigma_fn\"],\n",
    "    sigma_deriv_fn=FORMULATION[\"sigma_deriv_fn\"],\n",
    "    nsr_inv_fn=FORMULATION[\"nsr_inv_fn\"],\n",
    "    prediction_type=\"epsilon\",\n",
    "    algorithm_type=\"ode\",\n",
    "    timestep_schedule=\"cosine_lognsr\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_inference_result(pipeline, batch_size, num_inference_steps, seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test NCSN's Formulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FORMULATION = SAMPLER_FORMULATION_TABLE[\"NCSN\"]\n",
    "\n",
    "pipeline.scheduler = GaussianModelScheduler(\n",
    "    t_min=1e-4,\n",
    "    t_max=1e+4,\n",
    "    sigma_data=1.0,\n",
    "    scale_fn=FORMULATION[\"scale_fn\"],\n",
    "    scale_deriv_fn=FORMULATION[\"scale_deriv_fn\"],\n",
    "    sigma_fn=FORMULATION[\"sigma_fn\"],\n",
    "    sigma_deriv_fn=FORMULATION[\"sigma_deriv_fn\"],\n",
    "    nsr_inv_fn=FORMULATION[\"nsr_inv_fn\"],\n",
    "    prediction_type=\"epsilon\",\n",
    "    algorithm_type=\"ode\",\n",
    "    timestep_schedule=\"cosine_lognsr\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_inference_result(pipeline, batch_size, num_inference_steps, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "\n",
    "samples = torch.distributions.MultivariateNormal(\n",
    "    loc=mu,\n",
    "    covariance_matrix=cov\n",
    ").sample((batch_size,)).cpu().numpy()\n",
    "\n",
    "plt.hist2d(samples[:, 0], samples[:, 1], bins=[128, 128], range=[[-4, 4], [-4, 4]], cmap=\"plasma\", cmin=1)\n",
    "plt.title(\"Ground Truth\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
