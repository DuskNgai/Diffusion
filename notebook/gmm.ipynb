{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
    "os.environ[\"HF_HOME\"] = str(Path.cwd().joinpath(\"cache\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Scheduler by Gaussian Mixture Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from gaussian import (\n",
    "    GaussianModelScheduler as GaussianMixtureModelScheduler,\n",
    "    GaussianModelPipeline as GaussianMixtureModelPipeline,\n",
    ")\n",
    "from gmm import GaussianMixtureModel\n",
    "from sampler import SAMPLER_FORMULATION_TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_inference_result(\n",
    "    pipeline: GaussianMixtureModelPipeline,\n",
    "    batch_size: int,\n",
    "    num_inference_steps: int,\n",
    "    seed: int\n",
    "):\n",
    "    plt.figure(figsize=(16, 22))\n",
    "\n",
    "    algorithm_types = [\"ode\", \"sde\"]\n",
    "    prediction_types = [\"epsilon\", \"sample\", \"velocity\"]\n",
    "    timestep_schedules = [\"linear_lognsr\", \"cosine_lognsr\", \"power_lognsr\", \"uniform\"]\n",
    "\n",
    "    for row_id, (algorithm_type, prediction_type) in enumerate(itertools.product(algorithm_types, prediction_types)):\n",
    "        pipeline.scheduler.config.algorithm_type = algorithm_type\n",
    "        pipeline.scheduler.config.prediction_type = prediction_type\n",
    "        for col_id, timestep_schedule in enumerate(timestep_schedules):\n",
    "            if algorithm_type == \"sde\" and prediction_type == \"velocity\":\n",
    "                continue\n",
    "            pipeline.scheduler.config.timestep_schedule = timestep_schedule\n",
    "            torch.manual_seed(seed)\n",
    "            torch.cuda.manual_seed(seed)\n",
    "\n",
    "            samples = pipeline(batch_size=batch_size, num_inference_steps=num_inference_steps)\n",
    "            samples = samples.detach().cpu().numpy()\n",
    "            mean, std = samples.mean(axis=0), samples.std(axis=0)\n",
    "            print(mean, std)\n",
    "\n",
    "            plt.subplot(len(algorithm_types) * len(prediction_types), len(timestep_schedules), row_id * len(timestep_schedules) + col_id + 1)\n",
    "            plt.hist2d(samples[:, 0], samples[:, 1], bins=[256, 256], range=[[-3, 3], [-3, 3]], cmap=\"plasma\", cmin=1)\n",
    "            plt.title(f\"{algorithm_type} {prediction_type} {timestep_schedule}\")\n",
    "            plt.axis(\"equal\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "batch_size = 16384\n",
    "num_inference_steps = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Rectified Flow's Formulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FORMULATION = SAMPLER_FORMULATION_TABLE[\"Rectified Flow\"]\n",
    "\n",
    "pipeline = GaussianMixtureModelPipeline(\n",
    "    GaussianMixtureModel(\n",
    "        num_groups_per_model=8,\n",
    "        num_gs_per_group=8,\n",
    "        model_radius=2,\n",
    "        group_radius=0.4,\n",
    "        sigma=0.04\n",
    "    ),\n",
    "    GaussianMixtureModelScheduler(\n",
    "        t_min=0.0001,\n",
    "        t_max=0.9999,\n",
    "        sigma_data=1.0,\n",
    "        scale_fn=FORMULATION[\"scale_fn\"],\n",
    "        scale_deriv_fn=FORMULATION[\"scale_deriv_fn\"],\n",
    "        sigma_fn=FORMULATION[\"sigma_fn\"],\n",
    "        sigma_deriv_fn=FORMULATION[\"sigma_deriv_fn\"],\n",
    "        nsr_inv_fn=FORMULATION[\"nsr_inv_fn\"],\n",
    "        prediction_type=\"epsilon\",\n",
    "        algorithm_type=\"ode\",\n",
    "        timestep_schedule=\"cosine_lognsr\"\n",
    "    )\n",
    ")\n",
    "if torch.cuda.is_available():\n",
    "    pipeline = pipeline.to(device=torch.device(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_inference_result(pipeline, batch_size, num_inference_steps, seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test EDM's Formulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FORMULATION = SAMPLER_FORMULATION_TABLE[\"EDM\"]\n",
    "\n",
    "pipeline.scheduler = GaussianMixtureModelScheduler(\n",
    "    t_min=0.001,\n",
    "    t_max=100.0,\n",
    "    sigma_data=1.0,\n",
    "    scale_fn=FORMULATION[\"scale_fn\"],\n",
    "    scale_deriv_fn=FORMULATION[\"scale_deriv_fn\"],\n",
    "    sigma_fn=FORMULATION[\"sigma_fn\"],\n",
    "    sigma_deriv_fn=FORMULATION[\"sigma_deriv_fn\"],\n",
    "    nsr_inv_fn=FORMULATION[\"nsr_inv_fn\"],\n",
    "    prediction_type=\"epsilon\",\n",
    "    algorithm_type=\"ode\",\n",
    "    timestep_schedule=\"cosine_lognsr\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_inference_result(pipeline, batch_size, num_inference_steps, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "\n",
    "samples = torch.distributions.Normal(\n",
    "    loc=pipeline.model.mu.detach().cpu(),\n",
    "    scale=pipeline.model.sigma\n",
    ").sample((batch_size // len(pipeline.model.mu.detach().cpu()),)).reshape(-1, 2).cpu().numpy()\n",
    "\n",
    "plt.hist2d(samples[:, 0], samples[:, 1], bins=[256, 256], range=[[-3, 3], [-3, 3]], cmap=\"plasma\", cmin=1)\n",
    "plt.title(\"Ground Truth\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
